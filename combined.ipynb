{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark import Lark, Tree\n",
    "from lexer import Lexer as Lexer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "    start: statements\n",
    "\n",
    "    statements: statement+\n",
    "\n",
    "    statement: print_statement END_OF_STATEMENT\n",
    "             | declaration END_OF_STATEMENT\n",
    "             | exception_handling\n",
    "             | return_statement END_OF_STATEMENT\n",
    "             | control_flow\n",
    "             | expression_statement\n",
    "\n",
    "    print_statement: PRINT_KEYWORD ROUND_OPEN print_args ROUND_CLOSE\n",
    "\n",
    "    print_args: (expression) (COMMA print_args)?\n",
    "\n",
    "    expression_statement: expression END_OF_STATEMENT\n",
    "                        | assignment END_OF_STATEMENT\n",
    "\n",
    "    expression: expression (operator|comparator) expression\n",
    "              | unary_expression\n",
    "              | identifier\n",
    "              | function_call\n",
    "              | identifier index\n",
    "              | ROUND_OPEN expression ROUND_CLOSE\n",
    "              | literal\n",
    "              | identifier COMPOUND_OPERATOR expression\n",
    "              | identifier DOT_OPERATOR identifier expression\n",
    "\n",
    "    unary_expression: unary_operator identifier | identifier unary_operator\n",
    "                    | NOT_OPERATOR (identifier | ROUND_OPEN expression ROUND_CLOSE)\n",
    "\n",
    "    assignment: identifier ASSIGNMENT_OPERATOR expression\n",
    "              | identifier ASSIGNMENT_OPERATOR assignment_list\n",
    "\n",
    "    assignment_list: (literal|identifier) COMMA (literal|identifier) (COMMA (literal|identifier))*\n",
    "\n",
    "    index: (index?) SQUARE_OPEN expression SQUARE_CLOSE\n",
    "\n",
    "    control_flow: FUNCTION_DECLARATION identifier ROUND_OPEN parameters ROUND_CLOSE block\n",
    "                | IF_ELIF ROUND_OPEN expression ROUND_CLOSE block (ELSE_KEYWORD block)?\n",
    "                | WHILE_KEYWORD ROUND_OPEN expression ROUND_CLOSE block\n",
    "                | DO_KEYWORD block WHILE_KEYWORD ROUND_OPEN expression ROUND_CLOSE\n",
    "                | FOR_KEYWORD ROUND_OPEN dec_control_flow END_OF_STATEMENT expression END_OF_STATEMENT (expression | assignment) ROUND_CLOSE block\n",
    "                | BREAK_CONTINUE END_OF_STATEMENT\n",
    "\n",
    "    dec_control_flow: VARIABLE_DECLARATION identifier ASSIGNMENT_OPERATOR expression\n",
    "\n",
    "    declaration: TUPLE_DECLARATION identifier ASSIGNMENT_OPERATOR SQUARE_OPEN expression (COMMA expression)* SQUARE_CLOSE\n",
    "                | LIST_DECLARATION identifier ASSIGNMENT_OPERATOR list_content\n",
    "                | ARR_DECLARATION identifier ASSIGNMENT_OPERATOR SQUARE_OPEN literal (COMMA literal)* SQUARE_CLOSE\n",
    "                | EXCEPTION_TYPE identifier ASSIGNMENT_OPERATOR identifier\n",
    "                | LIST_DECLARATION identifier ASSIGNMENT_OPERATOR matrix\n",
    "                | ARR_DECLARATION identifier ASSIGNMENT_OPERATOR matrix\n",
    "                | VARIABLE_DECLARATION identifier (COMMA identifier)* ASSIGNMENT_OPERATOR expression (COMMA (expression))*\n",
    "\n",
    "    list_content: SQUARE_OPEN expression (COMMA expression)* SQUARE_CLOSE\n",
    "                | SQUARE_OPEN SQUARE_CLOSE\n",
    "\n",
    "    matrix: SQUARE_OPEN items SQUARE_CLOSE\n",
    "\n",
    "    items: matrix (COMMA matrix)*\n",
    "\n",
    "    exception_handling: TRY_KEYWORD block CATCH_KEYWORD ROUND_OPEN EXCEPTION_TYPE identifier ROUND_CLOSE block FINALLY_KEYWORD block\n",
    "                      | THROW_KEYWORD EXCEPTION_TYPE ROUND_OPEN print_args ROUND_CLOSE END_OF_STATEMENT\n",
    "\n",
    "    block: CURLY_OPEN statements CURLY_CLOSE | CURLY_OPEN CURLY_CLOSE\n",
    "\n",
    "    function_call: identifier ROUND_OPEN arguments ROUND_CLOSE\n",
    "                 | identifier DOT_OPERATOR identifier ROUND_OPEN arguments ROUND_CLOSE\n",
    "\n",
    "    return_statement: RETURN_KEYWORD expression?\n",
    "\n",
    "    operator: OPERATOR\n",
    "\n",
    "    compound_operator: COMPOUND_OPERATOR\n",
    "\n",
    "    unary_operator: UNARY_OPERATOR\n",
    "\n",
    "    comparator: COMPARATOR\n",
    "\n",
    "    identifier: IDENTIFIER\n",
    "\n",
    "    literal: integer_constant\n",
    "           | decimal_constant\n",
    "           | string_literal\n",
    "           | BOOLEAN_VALUE \n",
    "           | NULL_KEYWORD\n",
    "\n",
    "    keywords: KEYWORD\n",
    "\n",
    "    integer_constant: INTEGER_CONSTANT\n",
    "\n",
    "    decimal_constant: DECIMAL_CONSTANT\n",
    "\n",
    "    string_literal: STRING_LITERAL\n",
    "\n",
    "    arguments: (COMMA | expression)*\n",
    "\n",
    "    parameters: parameter (COMMA parameter)*\n",
    "              | (COMMA expression)*\n",
    "\n",
    "    parameter: (VARIABLE_DECLARATION | LIST_DECLARATION | ARR_DECLARATION | TUPLE_DECLARATION) identifier\n",
    "    %declare STRING_LITERAL BOOLEAN_VALUE COMMA FUNCTION_DECLARATION BREAK_CONTINUE IF_ELIF ELSE_KEYWORD WHILE_KEYWORD DO_KEYWORD FOR_KEYWORD PRINT_KEYWORD RETURN_KEYWORD VARIABLE_DECLARATION LIST_DECLARATION ARR_DECLARATION TUPLE_DECLARATION EXCEPTION_TYPE NULL_KEYWORD TRY_KEYWORD CATCH_KEYWORD FINALLY_KEYWORD THROW_KEYWORD KEYWORD NOT_OPERATOR ASSIGNMENT_OPERATOR OPERATOR COMPOUND_OPERATOR UNARY_OPERATOR COMPARATOR DOT_OPERATOR PUNCTUATION END_OF_STATEMENT ROUND_OPEN ROUND_CLOSE CURLY_OPEN CURLY_CLOSE SQUARE_OPEN SQUARE_CLOSE DECIMAL_CONSTANT INTEGER_CONSTANT IDENTIFIER QUOTATION ERROR\n",
    "    %import common.WS\n",
    "    %ignore WS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark.lexer import Lexer, Token\n",
    "\n",
    "class MyLexer(Lexer):\n",
    "    def __init__(self, lexer_conf):\n",
    "        pass\n",
    "\n",
    "    def lex(self, data):\n",
    "        lexer = Lexer_(source_code=data)\n",
    "        lexer.tokenize()\n",
    "        tokens = lexer.get_tokens()\n",
    "        for type, value in tokens:\n",
    "            yield Token(type, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['const', 'a', '=', '5', ';', 'var', 'b', '=', '5', ';']\n",
      "+-start\n",
      "  |\n",
      "  +-statements\n",
      "    |\n",
      "    +-statement\n",
      "      |\n",
      "      +-declaration\n",
      "        |\n",
      "        +-const\n",
      "        |\n",
      "        +-identifier\n",
      "          |\n",
      "          +-a\n",
      "        |\n",
      "        +-=\n",
      "        |\n",
      "        +-expression\n",
      "          |\n",
      "          +-literal\n",
      "            |\n",
      "            +-integer_constant\n",
      "              |\n",
      "              +-5\n",
      "      |\n",
      "      +-;\n",
      "    |\n",
      "    +-statement\n",
      "      |\n",
      "      +-declaration\n",
      "        |\n",
      "        +-var\n",
      "        |\n",
      "        +-identifier\n",
      "          |\n",
      "          +-b\n",
      "        |\n",
      "        +-=\n",
      "        |\n",
      "        +-expression\n",
      "          |\n",
      "          +-literal\n",
      "            |\n",
      "            +-integer_constant\n",
      "              |\n",
      "              +-5\n",
      "      |\n",
      "      +-;\n",
      "Parsing successful.\n"
     ]
    }
   ],
   "source": [
    "parser = Lark(grammar, start='start', lexer=MyLexer, parser='lalr')\n",
    "\n",
    "input_string = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "def visualize_tree(tree, depth=0):\n",
    "    if isinstance(tree, Tree):\n",
    "        print(\"  \" * depth + \"+-\" + str(tree.data))\n",
    "        for child in tree.children[:-1]:\n",
    "            print(\"  \" * (depth + 1) + \"|\")\n",
    "            visualize_tree(child, depth + 1)\n",
    "        if tree.children:\n",
    "            print(\"  \" * (depth + 1) + \"|\")\n",
    "            visualize_tree(tree.children[-1], depth + 1)\n",
    "    else:\n",
    "        print(\"  \" * depth + \"+-\" + str(tree))\n",
    "\n",
    "try:\n",
    "    tree = parser.parse(input_string)\n",
    "    visualize_tree(tree)\n",
    "    print(\"Parsing successful.\")\n",
    "except Exception as e:\n",
    "    print(\"Parsing failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['print', '10', ';', 'var', 'x', '=', '5', ';', 'var', 'y', '=', 'true', ';', 'x', '=', '10', ';', 'x', '=', 'y', ';']\n"
     ]
    },
    {
     "ename": "UnexpectedToken",
     "evalue": "Unexpected token Token('INTEGER_CONSTANT', '10') at line None, column None.\nExpected one of: \n\t* ROUND_OPEN\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/compilers/lib/python3.11/site-packages/lark/parsers/lalr_parser.py:126\u001b[0m, in \u001b[0;36mParserState.feed_token\u001b[0;34m(self, token, is_end)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     action, arg \u001b[38;5;241m=\u001b[39m \u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'INTEGER_CONSTANT'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnexpectedToken\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 123\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m    115\u001b[0m source_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124mprint 10;\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124mvar x = 5;\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124mx = y;\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 123\u001b[0m ast \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(ast)\n",
      "Cell \u001b[0;32mIn[123], line 111\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(text):\n\u001b[0;32m--> 111\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformer\u001b[38;5;241m.\u001b[39mtransform(tree)\n",
      "File \u001b[0;32m~/anaconda3/envs/compilers/lib/python3.11/site-packages/lark/lark.py:625\u001b[0m, in \u001b[0;36mLark.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, start: Optional[\u001b[38;5;28mstr\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, on_error: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptional[Callable[[UnexpectedInput], bool]]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParseTree\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse the given text, according to the options provided.\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m \n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/compilers/lib/python3.11/site-packages/lark/parser_frontends.py:96\u001b[0m, in \u001b[0;36mParsingFrontend.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m     94\u001b[0m kw \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_error\u001b[39m\u001b[38;5;124m'\u001b[39m: on_error}\n\u001b[1;32m     95\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_lexer_thread(text)\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/compilers/lib/python3.11/site-packages/lark/parsers/lalr_parser.py:41\u001b[0m, in \u001b[0;36mLALR_Parser.parse\u001b[0;34m(self, lexer, start, on_error)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, lexer, start, on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/compilers/lib/python3.11/site-packages/lark/parsers/lalr_parser.py:171\u001b[0m, in \u001b[0;36m_Parser.parse\u001b[0;34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_interactive:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InteractiveParser(\u001b[38;5;28mself\u001b[39m, parser_state, parser_state\u001b[38;5;241m.\u001b[39mlexer)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_from_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/compilers/lib/python3.11/site-packages/lark/parsers/lalr_parser.py:188\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n",
      "File \u001b[0;32m~/anaconda3/envs/compilers/lib/python3.11/site-packages/lark/parsers/lalr_parser.py:179\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    177\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m state\u001b[38;5;241m.\u001b[39mlexer\u001b[38;5;241m.\u001b[39mlex(state):\n\u001b[0;32m--> 179\u001b[0m     \u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m end_token \u001b[38;5;241m=\u001b[39m Token\u001b[38;5;241m.\u001b[39mnew_borrow_pos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$END\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, token) \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;28;01melse\u001b[39;00m Token(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$END\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\u001b[38;5;241m.\u001b[39mfeed_token(end_token, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/compilers/lib/python3.11/site-packages/lark/parsers/lalr_parser.py:129\u001b[0m, in \u001b[0;36mParserState.feed_token\u001b[0;34m(self, token, is_end)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     expected \u001b[38;5;241m=\u001b[39m {s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m states[state]\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39misupper()}\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, expected, state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, interactive_parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m arg \u001b[38;5;241m!=\u001b[39m end_state\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m Shift:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# shift once and return\u001b[39;00m\n",
      "\u001b[0;31mUnexpectedToken\u001b[0m: Unexpected token Token('INTEGER_CONSTANT', '10') at line None, column None.\nExpected one of: \n\t* ROUND_OPEN\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, ast_utils, Transformer, v_args\n",
    "from dataclasses import dataclass\n",
    "from lark.tree import Meta\n",
    "import sys\n",
    "\n",
    "this_module = sys.modules[__name__]\n",
    "\n",
    "# Define AST classes\n",
    "class _Ast(ast_utils.Ast):\n",
    "    pass\n",
    "\n",
    "class _Statement(_Ast):\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class Value(_Ast, ast_utils.WithMeta):\n",
    "    meta: Meta\n",
    "    value: object\n",
    "\n",
    "@dataclass\n",
    "class Name(_Ast):\n",
    "    name: str\n",
    "\n",
    "@dataclass\n",
    "class CodeBlock(_Ast, ast_utils.AsList):\n",
    "    statements: list[_Statement]\n",
    "\n",
    "@dataclass\n",
    "class PrintStatement(_Statement):\n",
    "    expression: Value\n",
    "\n",
    "@dataclass\n",
    "class Declaration(_Statement):\n",
    "    identifier: str\n",
    "    value: Value\n",
    "\n",
    "@dataclass\n",
    "class ExceptionHandling(_Statement):\n",
    "    try_block: CodeBlock\n",
    "    catch_block: CodeBlock\n",
    "    finally_block: CodeBlock\n",
    "\n",
    "@dataclass\n",
    "class ReturnStatement(_Statement):\n",
    "    expression: Value\n",
    "\n",
    "@dataclass\n",
    "class ControlFlow(_Statement):\n",
    "    condition: Value\n",
    "    block: CodeBlock\n",
    "\n",
    "@dataclass\n",
    "class Assignment(_Statement):\n",
    "    identifier: str\n",
    "    index: Value\n",
    "    value: Value\n",
    "\n",
    "@dataclass\n",
    "class Expression(_Ast):\n",
    "    left: Value\n",
    "    operator: str\n",
    "    right: Value\n",
    "\n",
    "class ToAst(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def statements(self, items):\n",
    "        return CodeBlock(statements=items)\n",
    "\n",
    "    def print_statement(self, items):\n",
    "        return PrintStatement(expression=items[0])\n",
    "\n",
    "    def declaration(self, items):\n",
    "        return Declaration(identifier=items[0], value=items[1])\n",
    "\n",
    "    def exception_handling(self, items):\n",
    "        return ExceptionHandling(try_block=items[0], catch_block=items[1], finally_block=items[2])\n",
    "\n",
    "    def return_statement(self, items):\n",
    "        return ReturnStatement(expression=items[0])\n",
    "\n",
    "    def control_flow(self, items):\n",
    "        return ControlFlow(condition=items[0], block=items[1])\n",
    "\n",
    "    def assignment(self, items):\n",
    "        return Assignment(identifier=items[0], index=items[1], value=items[2])\n",
    "\n",
    "    def expression(self, items):\n",
    "        return Expression(left=items[0], operator=items[1], right=items[2])\n",
    "\n",
    "    def STRING(self, value):\n",
    "        return value[1:-1]\n",
    "\n",
    "    def INTEGER_CONSTANT(self, value):\n",
    "        return int(value)\n",
    "\n",
    "    def DECIMAL_CONSTANT(self, value):\n",
    "        return float(value)\n",
    "\n",
    "    def IDENTIFIER(self, value):\n",
    "        return Name(name=value)\n",
    "\n",
    "    def BOOLEAN_VALUE(self, value):\n",
    "        return Value(meta=None, value=value.lower() == 'true')\n",
    "\n",
    "parser = Lark(grammar, start='start', transformer=ToAst(), lexer=MyLexer, parser='lalr')\n",
    "transformer = ast_utils.create_transformer(this_module, ToAst())\n",
    "\n",
    "def parse(text):\n",
    "    tree = parser.parse(text)\n",
    "    return transformer.transform(tree)\n",
    "\n",
    "# Example usage\n",
    "source_code = \"\"\"\n",
    "print 10;\n",
    "var x = 5;\n",
    "var y = true;\n",
    "x = 10;\n",
    "x = y;\n",
    "\"\"\"\n",
    "\n",
    "ast = parse(source_code)\n",
    "print(ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
